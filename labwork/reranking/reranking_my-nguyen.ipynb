{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPlo/H04r3M1bOOe0zHw61m"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Package Installation and Imports"],"metadata":{"id":"-qR30XnbtGNq"}},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"m2BrJgI_squG"},"outputs":[],"source":["# Install required packages\n","!pip install langchain langchain-openai python-dotenv sentence-transformers"]},{"cell_type":"code","source":["# Clone the repository to access helper functions and evaluation modules\n","!git clone https://github.com/NirDiamant/RAG_TECHNIQUES.git\n","import sys\n","sys.path.append('RAG_TECHNIQUES')\n","# If you need to run with the latest data\n","# !cp -r RAG_TECHNIQUES/data ."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"82trThoDtWAA","executionInfo":{"status":"ok","timestamp":1769073031372,"user_tz":-420,"elapsed":133,"user":{"displayName":"Nguyen Thi Tra My B2207544","userId":"14497950818613580693"}},"outputId":"9b3468ba-ec35-4a02-8262-ab444d70e92d"},"execution_count":124,"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'RAG_TECHNIQUES' already exists and is not an empty directory.\n"]}]},{"cell_type":"code","source":["import os\n","import sys\n","# from langchain.docstore.document import Document\n","from langchain_core.documents import Document as LangchainDocument\n","from typing import List, Dict, Any, Tuple\n","from langchain_openai import ChatOpenAI\n","# from langchain.chains import RetrievalQA\n","from langchain_core.retrievers import BaseRetriever\n","from sentence_transformers import CrossEncoder\n","\n","from google.colab import userdata\n","\n","\n","# Set the OpenAI API key environment variable\n","OPENAI_API_KEY = userdata.get('key_openai')"],"metadata":{"id":"uuwc2MRLtcBC","executionInfo":{"status":"ok","timestamp":1769073031915,"user_tz":-420,"elapsed":542,"user":{"displayName":"Nguyen Thi Tra My B2207544","userId":"14497950818613580693"}}},"execution_count":125,"outputs":[]},{"cell_type":"code","source":["# from helper_functions import *"],"metadata":{"id":"tdThmbKQAWw-","executionInfo":{"status":"ok","timestamp":1769073031937,"user_tz":-420,"elapsed":21,"user":{"displayName":"Nguyen Thi Tra My B2207544","userId":"14497950818613580693"}}},"execution_count":126,"outputs":[]},{"cell_type":"code","source":["!pip install langchain-community"],"metadata":{"id":"T61WLfs5lH5L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain_community.document_loaders.pdf import PyPDFLoader"],"metadata":{"id":"47ljgWH50fqr","executionInfo":{"status":"ok","timestamp":1769073047716,"user_tz":-420,"elapsed":1,"user":{"displayName":"Nguyen Thi Tra My B2207544","userId":"14497950818613580693"}}},"execution_count":128,"outputs":[]},{"cell_type":"code","source":["from langchain_text_splitters import RecursiveCharacterTextSplitter"],"metadata":{"id":"HZTLG6WMAwMu","executionInfo":{"status":"ok","timestamp":1769073047756,"user_tz":-420,"elapsed":1,"user":{"displayName":"Nguyen Thi Tra My B2207544","userId":"14497950818613580693"}}},"execution_count":129,"outputs":[]},{"cell_type":"code","source":["from langchain_openai import OpenAIEmbeddings"],"metadata":{"id":"2r3C6m2zA4gP","executionInfo":{"status":"ok","timestamp":1769073047758,"user_tz":-420,"elapsed":1,"user":{"displayName":"Nguyen Thi Tra My B2207544","userId":"14497950818613580693"}}},"execution_count":130,"outputs":[]},{"cell_type":"code","source":["!pip install langchain[faiss]"],"metadata":{"id":"TzczDuKyBE7s","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1769073060138,"user_tz":-420,"elapsed":12380,"user":{"displayName":"Nguyen Thi Tra My B2207544","userId":"14497950818613580693"}},"outputId":"bc9c843e-8668-4c94-f443-0f401e0683a2"},"execution_count":131,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: langchain[faiss] in /usr/local/lib/python3.12/dist-packages (1.2.4)\n","\u001b[33mWARNING: langchain 1.2.4 does not provide the extra 'faiss'\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: langchain-core<2.0.0,>=1.2.1 in /usr/local/lib/python3.12/dist-packages (from langchain[faiss]) (1.2.7)\n","Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langchain[faiss]) (1.0.6)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain[faiss]) (2.12.3)\n","Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain[faiss]) (1.33)\n","Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain[faiss]) (0.6.4)\n","Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain[faiss]) (25.0)\n","Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain[faiss]) (6.0.3)\n","Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain[faiss]) (9.1.2)\n","Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain[faiss]) (4.15.0)\n","Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain[faiss]) (0.13.0)\n","Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain[faiss]) (4.0.0)\n","Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain[faiss]) (1.0.6)\n","Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain[faiss]) (0.3.3)\n","Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain[faiss]) (3.6.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain[faiss]) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain[faiss]) (2.41.4)\n","Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain[faiss]) (0.4.2)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.1->langchain[faiss]) (3.0.0)\n","Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain[faiss]) (1.12.1)\n","Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain[faiss]) (0.28.1)\n","Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain[faiss]) (3.11.5)\n","Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain[faiss]) (1.0.0)\n","Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain[faiss]) (2.32.5)\n","Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain[faiss]) (0.25.0)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain[faiss]) (4.12.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain[faiss]) (2026.1.4)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain[faiss]) (1.0.9)\n","Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain[faiss]) (3.11)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain[faiss]) (0.16.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain[faiss]) (3.4.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain[faiss]) (2.5.0)\n"]}]},{"cell_type":"code","source":["from langchain_community.vectorstores import FAISS"],"metadata":{"id":"eCIPJDMkA-vF","executionInfo":{"status":"ok","timestamp":1769073060251,"user_tz":-420,"elapsed":3,"user":{"displayName":"Nguyen Thi Tra My B2207544","userId":"14497950818613580693"}}},"execution_count":132,"outputs":[]},{"cell_type":"markdown","source":["# Define the document's path"],"metadata":{"id":"IakDvBaI0FG9"}},{"cell_type":"code","source":["# Download required data files\n","import os\n","os.makedirs('data', exist_ok=True)\n","\n","# Download the PDF document used in this notebook\n","!wget -O data/Understanding_Climate_Change.pdf https://raw.githubusercontent.com/NirDiamant/RAG_TECHNIQUES/main/data/Understanding_Climate_Change.pdf\n","!wget -O data/Understanding_Climate_Change.pdf https://raw.githubusercontent.com/NirDiamant/RAG_TECHNIQUES/main/data/Understanding_Climate_Change.pdf\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m-feFmWH0DIE","executionInfo":{"status":"ok","timestamp":1769073060510,"user_tz":-420,"elapsed":258,"user":{"displayName":"Nguyen Thi Tra My B2207544","userId":"14497950818613580693"}},"outputId":"cafdabaa-fce4-44eb-f692-828c56e77a58"},"execution_count":133,"outputs":[{"output_type":"stream","name":"stdout","text":["--2026-01-22 09:11:00--  https://raw.githubusercontent.com/NirDiamant/RAG_TECHNIQUES/main/data/Understanding_Climate_Change.pdf\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 206372 (202K) [application/octet-stream]\n","Saving to: ‘data/Understanding_Climate_Change.pdf’\n","\n","\r          data/Unde   0%[                    ]       0  --.-KB/s               \rdata/Understanding_ 100%[===================>] 201.54K  --.-KB/s    in 0.02s   \n","\n","2026-01-22 09:11:00 (7.89 MB/s) - ‘data/Understanding_Climate_Change.pdf’ saved [206372/206372]\n","\n","--2026-01-22 09:11:00--  https://raw.githubusercontent.com/NirDiamant/RAG_TECHNIQUES/main/data/Understanding_Climate_Change.pdf\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 206372 (202K) [application/octet-stream]\n","Saving to: ‘data/Understanding_Climate_Change.pdf’\n","\n","data/Understanding_ 100%[===================>] 201.54K  --.-KB/s    in 0.02s   \n","\n","2026-01-22 09:11:00 (7.97 MB/s) - ‘data/Understanding_Climate_Change.pdf’ saved [206372/206372]\n","\n"]}]},{"cell_type":"code","source":["path = \"data/Understanding_Climate_Change.pdf\""],"metadata":{"id":"rmOHa_dz0LDG","executionInfo":{"status":"ok","timestamp":1769073060622,"user_tz":-420,"elapsed":4,"user":{"displayName":"Nguyen Thi Tra My B2207544","userId":"14497950818613580693"}}},"execution_count":134,"outputs":[]},{"cell_type":"markdown","source":["# Create a vector store"],"metadata":{"id":"gl9ocOm20NkQ"}},{"cell_type":"code","source":["# vectorstore = encode_pdf(path)\n"],"metadata":{"id":"5xMkmfYo0PHk","executionInfo":{"status":"ok","timestamp":1769073060624,"user_tz":-420,"elapsed":4,"user":{"displayName":"Nguyen Thi Tra My B2207544","userId":"14497950818613580693"}}},"execution_count":135,"outputs":[]},{"cell_type":"code","source":["from langchain_community.embeddings import HuggingFaceEmbeddings\n"],"metadata":{"id":"KI1wtJElFd-X","executionInfo":{"status":"ok","timestamp":1769073060627,"user_tz":-420,"elapsed":2,"user":{"displayName":"Nguyen Thi Tra My B2207544","userId":"14497950818613580693"}}},"execution_count":136,"outputs":[]},{"cell_type":"code","source":["\n","def create_vectorstore(file_path, chunk_size=1000, chunk_overlap=100, persist=False, persist_dir=\"vectorstore\"):\n","    \"\"\"\n","    Tạo vector store từ file PDF hoặc TXT.\n","\n","    Args:\n","        file_path (str): đường dẫn file tài liệu (.pdf hoặc .txt)\n","        chunk_size (int): số ký tự tối đa mỗi chunk\n","        chunk_overlap (int): số ký tự overlap giữa các chunk\n","        persist (bool): có lưu vectorstore ra disk không\n","        persist_dir (str): thư mục lưu vectorstore nếu persist=True\n","\n","    Returns:\n","        vectorstore: object vectorstore (FAISS)\n","    \"\"\"\n","\n","    # Load document\n","    ext = os.path.splitext(file_path)[1].lower()\n","    if ext == \".pdf\":\n","        loader = PyPDFLoader(file_path)\n","    elif ext == \".txt\":\n","        loader = TextLoader(file_path)\n","    else:\n","        raise ValueError(\"Chỉ hỗ trợ PDF hoặc TXT\")\n","\n","    documents = loader.load()\n","\n","    # Split thành chunks nhỏ\n","    text_splitter = RecursiveCharacterTextSplitter(\n","        chunk_size=chunk_size,\n","        chunk_overlap=chunk_overlap\n","    )\n","    docs = text_splitter.split_documents(documents)\n","\n","    # Tạo embeddings\n","    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n","    vectorstore = FAISS.from_documents(docs, embeddings)\n","\n","\n","    # Tạo vectorstore FAISS\n","    vectorstore = FAISS.from_documents(docs, embeddings)\n","\n","    # Lưu vectorstore nếu cần\n","    if persist:\n","        vectorstore.save_local(persist_dir)\n","\n","    return vectorstore\n"],"metadata":{"id":"yfLqElS41n1u","executionInfo":{"status":"ok","timestamp":1769073060630,"user_tz":-420,"elapsed":1,"user":{"displayName":"Nguyen Thi Tra My B2207544","userId":"14497950818613580693"}}},"execution_count":137,"outputs":[]},{"cell_type":"code","source":["!pip install faiss-cpu"],"metadata":{"id":"hWLIRma4GItl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1769073072473,"user_tz":-420,"elapsed":11842,"user":{"displayName":"Nguyen Thi Tra My B2207544","userId":"14497950818613580693"}},"outputId":"21575f3e-61ed-4e0f-808c-f894eb5dc2fe"},"execution_count":138,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.12/dist-packages (1.13.2)\n","Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n"]}]},{"cell_type":"code","source":["!pip install pypdf"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JydxpPmSllli","executionInfo":{"status":"ok","timestamp":1769073084608,"user_tz":-420,"elapsed":12128,"user":{"displayName":"Nguyen Thi Tra My B2207544","userId":"14497950818613580693"}},"outputId":"c3be5adf-c8d4-48d4-875d-76ce89781912"},"execution_count":139,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pypdf in /usr/local/lib/python3.12/dist-packages (6.6.0)\n"]}]},{"cell_type":"code","source":["vectorstore = create_vectorstore(\n","    path,\n","    chunk_size=2000,\n","    chunk_overlap=200,\n","    persist=True\n",")\n"],"metadata":{"id":"eYbYMhinF5bl","executionInfo":{"status":"ok","timestamp":1769073108290,"user_tz":-420,"elapsed":23637,"user":{"displayName":"Nguyen Thi Tra My B2207544","userId":"14497950818613580693"}}},"execution_count":140,"outputs":[]},{"cell_type":"markdown","source":["# Method 1: LLM based function to rerank the retrieved documents"],"metadata":{"id":"1nX7xWbs1u7Y"}},{"cell_type":"markdown","source":["# Create a custom reranking function"],"metadata":{"id":"KcHxcwsr1z4r"}},{"cell_type":"code","source":["from pydantic import BaseModel, Field"],"metadata":{"id":"Svp8BsJ01_88","executionInfo":{"status":"ok","timestamp":1769073108312,"user_tz":-420,"elapsed":20,"user":{"displayName":"Nguyen Thi Tra My B2207544","userId":"14497950818613580693"}}},"execution_count":141,"outputs":[]},{"cell_type":"code","source":["from langchain_core.prompts import PromptTemplate"],"metadata":{"id":"_GJCjldS2O-Z","executionInfo":{"status":"ok","timestamp":1769073108314,"user_tz":-420,"elapsed":1,"user":{"displayName":"Nguyen Thi Tra My B2207544","userId":"14497950818613580693"}}},"execution_count":142,"outputs":[]},{"cell_type":"code","source":["class RatingScore(BaseModel):\n","    relevance_score: float = Field(..., description=\"The relevance score of a document to a query.\")\n","\n","def rerank_documents(query: str, docs: List[LangchainDocument], top_n: int = 3) -> List[LangchainDocument]:\n","    prompt_template = PromptTemplate(\n","        input_variables=[\"query\", \"doc\"],\n","        template=\"\"\"On a scale of 1-10, rate the relevance of the following document to the query. Consider the specific context and intent of the query, not just keyword matches.\n","        Query: {query}\n","        Document: {doc}\n","        Relevance Score:\"\"\"\n","    )\n","\n","    llm = ChatOpenAI(\n","        model=\"gpt-4.1\", # Model's name\n","        temperature=0,\n","        max_tokens=4000,\n","        openai_api_key=userdata.get('key_ptn'), # PTN's key\n","        base_url=\"https://llm.ptnglobalcorp.com\"\n","    )\n","    llm_chain = prompt_template | llm.with_structured_output(RatingScore)\n","\n","    scored_docs = []\n","    for doc in docs:\n","        input_data = {\"query\": query, \"doc\": doc.page_content}\n","        score = llm_chain.invoke(input_data).relevance_score\n","        try:\n","            score = float(score)\n","        except ValueError:\n","            score = 0  # Default score if parsing fails\n","        scored_docs.append((doc, score))\n","\n","    reranked_docs = sorted(scored_docs, key=lambda x: x[1], reverse=True)\n","    return [doc for doc, _ in reranked_docs[:top_n]]"],"metadata":{"id":"cAqrZ73b1wSV","executionInfo":{"status":"ok","timestamp":1769073108336,"user_tz":-420,"elapsed":21,"user":{"displayName":"Nguyen Thi Tra My B2207544","userId":"14497950818613580693"}}},"execution_count":143,"outputs":[]},{"cell_type":"markdown","source":["# Example usage of the reranking function with a sample query relevant to the document"],"metadata":{"id":"X_1dWnAM27Ww"}},{"cell_type":"code","source":["query = \"What are the impacts of climate change on biodiversity?\"\n","initial_docs = vectorstore.similarity_search(query, k=15)\n","reranked_docs = rerank_documents(query, initial_docs)\n","\n","# print first 3 initial documents\n","print(\"Top initial documents:\")\n","for i, doc in enumerate(initial_docs[:3]):\n","    print(f\"\\nDocument {i+1}:\")\n","    print(doc.page_content[:200] + \"...\")  # Print first 200 characters of each document\n","\n","\n","# Print results\n","print(f\"Query: {query}\\n\")\n","print(\"Top reranked documents:\")\n","for i, doc in enumerate(reranked_docs):\n","    print(f\"\\nDocument {i+1}:\")\n","    print(doc.page_content[:200] + \"...\")  # Print first 200 characters of each document"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e4mCAsSo29bA","executionInfo":{"status":"ok","timestamp":1769073136310,"user_tz":-420,"elapsed":27973,"user":{"displayName":"Nguyen Thi Tra My B2207544","userId":"14497950818613580693"}},"outputId":"aec82332-1f2f-49d0-ef8c-64d2f8dff938"},"execution_count":144,"outputs":[{"output_type":"stream","name":"stdout","text":["Top initial documents:\n","\n","Document 1:\n","includes identifying climate refugia, areas less affected by climate change, and prioritizing \n","them for protection. Adaptive management practices ensure that conservation efforts remain \n","effective und...\n","\n","Document 2:\n","experiencing shifts in plant and animal species composition. These changes can lead to a loss \n","of biodiversity and disrupt ecological balance. \n","Marine Ecosystems \n","Marine ecosystems are highly vulnerab...\n","\n","Document 3:\n","goals. Policies should promote synergies between biodiversity conservation and climate \n","action. \n","Chapter 10: Climate Change and Human Health \n","Health Impacts \n","Heat-Related Illnesses \n","Rising temperature...\n","Query: What are the impacts of climate change on biodiversity?\n","\n","Top reranked documents:\n","\n","Document 1:\n","experiencing shifts in plant and animal species composition. These changes can lead to a loss \n","of biodiversity and disrupt ecological balance. \n","Marine Ecosystems \n","Marine ecosystems are highly vulnerab...\n","\n","Document 2:\n","includes identifying climate refugia, areas less affected by climate change, and prioritizing \n","them for protection. Adaptive management practices ensure that conservation efforts remain \n","effective und...\n","\n","Document 3:\n","Freshwater Ecosystems \n","Freshwater ecosystems, including rivers, lakes, and wetlands, are affected by changes in \n","precipitation patterns, temperature, and water flow. These changes can lead to altered ...\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"2wX93brlnGog"}},{"cell_type":"code","source":["from langchain_core.retrievers import BaseRetriever"],"metadata":{"id":"Mn9QRaE5nwEV","executionInfo":{"status":"ok","timestamp":1769073136311,"user_tz":-420,"elapsed":85,"user":{"displayName":"Nguyen Thi Tra My B2207544","userId":"14497950818613580693"}}},"execution_count":145,"outputs":[]},{"cell_type":"code","source":["# # Create a custom retriever class\n","# class CustomRetriever(BaseRetriever, BaseModel):\n","\n","#     vectorstore: Any = Field(description=\"Vector store for initial retrieval\")\n","\n","#     class Config:\n","#         arbitrary_types_allowed = True\n","\n","#     def get_relevant_documents(self, query: str, num_docs=2) -> List[Document]:\n","#         initial_docs = self.vectorstore.similarity_search(query, k=30)\n","#         return rerank_documents(query, initial_docs, top_n=num_docs)\n","\n","\n","# # Create the custom retriever\n","# custom_retriever = CustomRetriever(vectorstore=vectorstore)\n","\n","# # Create an LLM for answering questions\n","# llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n","\n","# # Create the RetrievalQA chain with the custom retriever\n","# qa_chain = RetrievalQA.from_chain_type(\n","#     llm=llm,\n","#     chain_type=\"stuff\",\n","#     retriever=custom_retriever,\n","#     return_source_documents=True\n","# )\n","\n","\"\"\" RetrievalQA cant import, so we replace it with another methods\"\"\"\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"xRvZhxCEvXB-","executionInfo":{"status":"ok","timestamp":1769073136313,"user_tz":-420,"elapsed":55,"user":{"displayName":"Nguyen Thi Tra My B2207544","userId":"14497950818613580693"}},"outputId":"80de05db-44ac-4909-8e56-879211229d38"},"execution_count":146,"outputs":[{"output_type":"execute_result","data":{"text/plain":["' RetrievalQA cant import, so we replace it with another methods'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":146}]},{"cell_type":"code","source":["class RetrievalQA(BaseModel):\n","    \"\"\"\n","    Minimal replacement for RetrievalQA for LangChain 1.2.6\n","    Keeps the same interface:\n","        - from_chain_type\n","        - return_source_documents\n","        - run / __call__ interface\n","    \"\"\"\n","    llm: Any\n","    retriever: BaseRetriever\n","    return_source_documents: bool = True\n","    # combine_documents_chain: Any = None  # Stuff chain\n","    # Minimal prompt\n","    prompt_template: str= \"\"\"You are a helpful assistant.\n","Use ONLY the following context to answer the question.\n","If the answer is not in the context, say \"I don't know\".\n","\n","Context:\n","{context}\n","\n","Question:\n","{input}\n","\n","Answer:\n","\"\"\"\n","\n","\n","    @classmethod\n","    def from_chain_type(cls, llm, retriever, chain_type=\"stuff\", return_source_documents=True):\n","        if chain_type != \"stuff\":\n","            raise NotImplementedError(\"Only 'stuff' chain is implemented in this custom class\")\n","        return cls(\n","            llm=llm,\n","            retriever=retriever,\n","            return_source_documents=return_source_documents\n","        )\n","\n","        # combine_chain = create_stuff_documents_chain(llm=llm, prompt=prompt)\n","\n","        return cls(\n","            llm=llm,\n","            retriever=retriever,\n","            return_source_documents=return_source_documents,\n","            # combine_documents_chain=combine_chain\n","        )\n","\n","    def __call__(self, inputs: Dict[str, str]) -> Dict[str, Any]:\n","        query = inputs.get(\"query\") or inputs.get(\"input\")\n","        if not query:\n","            raise ValueError(\"You must provide 'query' or 'input' key\")\n","\n","        # Retrieve documents\n","        docs: List[LangchainDocument] = self.retriever.get_relevant_documents(query)\n","\n","        # Run combine_documents_chain\n","        # answer = self.combine_documents_chain.run(docs, question=query)\n","        context = \"\\n\\n\".join([doc.page_content for doc in docs])\n","\n","\n","        #  Create prompt\n","        final_prompt = self.prompt_template.format(context=context, input=query)\n","\n","        # Call directly LLMs\n","        answer = self.llm.invoke(final_prompt)\n","\n","        # Return in same format as original RetrievalQA\n","        result = {\"result\": answer}\n","        if self.return_source_documents:\n","            result[\"source_documents\"] = docs\n","        return result\n","\n","    def run(self, query: str) -> str:\n","        return self.__call__({\"query\": query})[\"result\"]\n"],"metadata":{"id":"S6TwlGXxwkzY","executionInfo":{"status":"ok","timestamp":1769073136315,"user_tz":-420,"elapsed":38,"user":{"displayName":"Nguyen Thi Tra My B2207544","userId":"14497950818613580693"}}},"execution_count":147,"outputs":[]},{"cell_type":"code","source":["# Create a custom retriever class\n","class CustomRetriever(BaseRetriever, BaseModel):\n","\n","    vectorstore: Any = Field(description=\"Vector store for initial retrieval\")\n","\n","    class Config:\n","        arbitrary_types_allowed = True\n","    # abstract method\n","    def _get_relevant_documents(self, query: str, num_docs=2) -> List[LangchainDocument]:\n","        initial_docs = self.vectorstore.similarity_search(query, k=30)\n","        return rerank_documents(query, initial_docs, top_n=num_docs)\n","\n","    # wrapper of BaseRetriever\n","    def get_relevant_documents(self, query: str, num_docs=2) -> List[LangchainDocument]:\n","        initial_docs = self.vectorstore.similarity_search(query, k=30)\n","        return rerank_documents(query, initial_docs, top_n=num_docs)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Am4WjFfnxmtJ","executionInfo":{"status":"ok","timestamp":1769073136329,"user_tz":-420,"elapsed":12,"user":{"displayName":"Nguyen Thi Tra My B2207544","userId":"14497950818613580693"}},"outputId":"31f2f9a6-63e7-4770-ab13-d9fc259f5cb7"},"execution_count":148,"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-3281216925.py:2: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n","  class CustomRetriever(BaseRetriever, BaseModel):\n"]}]},{"cell_type":"code","source":["custom_retriever = CustomRetriever(vectorstore=vectorstore)"],"metadata":{"id":"MmidCenmxXKH","executionInfo":{"status":"ok","timestamp":1769073136332,"user_tz":-420,"elapsed":1,"user":{"displayName":"Nguyen Thi Tra My B2207544","userId":"14497950818613580693"}}},"execution_count":149,"outputs":[]},{"cell_type":"code","source":["llm =  ChatOpenAI(\n","        model=\"gpt-4.1\", # Model's name\n","        temperature=0,\n","        max_tokens=4000,\n","        openai_api_key=userdata.get('key_ptn'), # PTN's key\n","        base_url=\"https://llm.ptnglobalcorp.com\"\n","    )"],"metadata":{"id":"PbP-MZjwxceo","executionInfo":{"status":"ok","timestamp":1769073137177,"user_tz":-420,"elapsed":844,"user":{"displayName":"Nguyen Thi Tra My B2207544","userId":"14497950818613580693"}}},"execution_count":150,"outputs":[]},{"cell_type":"code","source":["qa_chain = RetrievalQA.from_chain_type(\n","    llm=llm,\n","    retriever=custom_retriever,\n","    chain_type=\"stuff\",\n","    return_source_documents=True\n",")"],"metadata":{"id":"rpy-ItnnxiR4","executionInfo":{"status":"ok","timestamp":1769073137198,"user_tz":-420,"elapsed":19,"user":{"displayName":"Nguyen Thi Tra My B2207544","userId":"14497950818613580693"}}},"execution_count":151,"outputs":[]},{"cell_type":"markdown","source":["# Example query"],"metadata":{"id":"qlQhrqpjyalQ"}},{"cell_type":"code","source":["result = qa_chain({\"query\": query})\n","\n","print(f\"\\nQuestion: {query}\")\n","print(f\"Answer: {result['result']}\")\n","print(\"\\nRelevant source documents:\")\n","print(\"Sources:\", [doc.page_content[:200] for doc in result[\"source_documents\"]]) # Print first 200 characters of each document"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_mOmIO4LyY0O","executionInfo":{"status":"ok","timestamp":1769073194121,"user_tz":-420,"elapsed":56921,"user":{"displayName":"Nguyen Thi Tra My B2207544","userId":"14497950818613580693"}},"outputId":"c1c73b32-077d-4320-e6d7-6bb043c097e2"},"execution_count":152,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Question: What are the impacts of climate change on biodiversity?\n","Answer: content='Climate change impacts biodiversity by altering terrestrial ecosystems through shifting habitat ranges, changing species distributions, and impacting ecosystem functions. Forests, grasslands, and deserts are experiencing shifts in plant and animal species composition, which can lead to a loss of biodiversity and disrupt ecological balance. In marine ecosystems, rising sea temperatures, ocean acidification, and changing currents affect marine biodiversity, from coral reefs to deep-sea habitats. Species migration and changes in reproductive cycles can disrupt marine food webs and fisheries.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 96, 'prompt_tokens': 483, 'total_tokens': 579, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': None, 'reasoning_tokens': None, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_1a2c4a5ede', 'id': 'chatcmpl-D0l2W3M3KFHqHOqdqo4VSrslKfNEG', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019be4fa-ac7c-7733-975b-c4b06fbe9d57-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 483, 'output_tokens': 96, 'total_tokens': 579, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}}\n","\n","Relevant source documents:\n","Sources: ['experiencing shifts in plant and animal species composition. These changes can lead to a loss \\nof biodiversity and disrupt ecological balance. \\nMarine Ecosystems \\nMarine ecosystems are highly vulnerab', 'large-scale climate solutions. PPPs are particularly effective in areas such as infrastructure \\ndevelopment, renewable energy projects, and sustainable urban planning. \\nSocial and Cultural Change \\nBeh']\n"]}]},{"cell_type":"markdown","source":["# Example that demonstrates why we should use reranking"],"metadata":{"id":"N5P1Fdxk0mMn"}},{"cell_type":"code","source":["from langchain_community.embeddings import HuggingFaceEmbeddings"],"metadata":{"id":"5NBhXaUm5fVd","executionInfo":{"status":"ok","timestamp":1769073194129,"user_tz":-420,"elapsed":4,"user":{"displayName":"Nguyen Thi Tra My B2207544","userId":"14497950818613580693"}}},"execution_count":153,"outputs":[]},{"cell_type":"code","source":["    # load embedding_model\n","    embedding_model = HuggingFaceEmbeddings(\n","        model_name=\"thenlper/gte-small\",\n","        multi_process=True,\n","        # model_kwargs={\"device\": \"cuda\"},\n","        encode_kwargs={\n","            \"normalize_embeddings\": True\n","        },  # set True to compute cosine similarity\n","    )"],"metadata":{"id":"fB5aP9-A6BRh","executionInfo":{"status":"ok","timestamp":1769073195104,"user_tz":-420,"elapsed":974,"user":{"displayName":"Nguyen Thi Tra My B2207544","userId":"14497950818613580693"}}},"execution_count":154,"outputs":[]},{"cell_type":"code","source":["chunks = [\n","    \"The capital of France is great.\",\n","    \"The capital of France is huge.\",\n","    \"The capital of France is beautiful.\",\n","    \"\"\"Have you ever visited Paris? It is a beautiful city where you can eat delicious food and see the Eiffel Tower.\n","    I really enjoyed all the cities in france, but its capital with the Eiffel Tower is my favorite city.\"\"\",\n","    \"I really enjoyed my trip to Paris, France. The city is beautiful and the food is delicious. I would love to visit again. Such a great capital city.\"\n","]\n","docs = [LangchainDocument(page_content=sentence) for sentence in chunks]\n","\n","\n","def compare_rag_techniques(query: str, docs: List[LangchainDocument] = docs) -> None:\n","    embeddings = embedding_model\n","    vectorstore = FAISS.from_documents(docs, embeddings)\n","    vectorstore = FAISS.from_documents(docs, embeddings)\n","\n","    print(\"Comparison of Retrieval Techniques\")\n","    print(\"==================================\")\n","    print(f\"Query: {query}\\n\")\n","\n","    print(\"Baseline Retrieval Result:\")\n","    baseline_docs = vectorstore.similarity_search(query, k=2)\n","    for i, doc in enumerate(baseline_docs):\n","        print(f\"\\nDocument {i+1}:\")\n","        print(doc.page_content)\n","\n","    print(\"\\nAdvanced Retrieval Result:\")\n","    custom_retriever = CustomRetriever(vectorstore=vectorstore)\n","    advanced_docs = custom_retriever.get_relevant_documents(query)\n","    for i, doc in enumerate(advanced_docs):\n","        print(f\"\\nDocument {i+1}:\")\n","        print(doc.page_content)\n","\n","\n","query = \"what is the capital of france?\"\n","compare_rag_techniques(query, docs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qSHMtuqV4gTk","executionInfo":{"status":"ok","timestamp":1769073465930,"user_tz":-420,"elapsed":270817,"user":{"displayName":"Nguyen Thi Tra My B2207544","userId":"14497950818613580693"}},"outputId":"be7d73ef-6fe9-4267-b167-7eb9f896d141"},"execution_count":155,"outputs":[{"output_type":"stream","name":"stdout","text":["Comparison of Retrieval Techniques\n","==================================\n","Query: what is the capital of france?\n","\n","Baseline Retrieval Result:\n","\n","Document 1:\n","The capital of France is great.\n","\n","Document 2:\n","The capital of France is huge.\n","\n","Advanced Retrieval Result:\n","\n","Document 1:\n","The capital of France is great.\n","\n","Document 2:\n","Have you ever visited Paris? It is a beautiful city where you can eat delicious food and see the Eiffel Tower.\n","    I really enjoyed all the cities in france, but its capital with the Eiffel Tower is my favorite city.\n"]}]},{"cell_type":"markdown","source":["# Method 2:Cross Encoder models"],"metadata":{"id":"PiXLwS9U9HZM"}},{"cell_type":"markdown","source":["# Define the cross encoder class"],"metadata":{"id":"PjOHCg4D9HV0"}},{"cell_type":"code","source":["cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n","\n","class CrossEncoderRetriever(BaseRetriever, BaseModel):\n","    vectorstore: Any = Field(description=\"Vector store for initial retrieval\")\n","    cross_encoder: Any = Field(description=\"Cross-encoder model for reranking\")\n","    k: int = Field(default=5, description=\"Number of documents to retrieve initially\")\n","    rerank_top_k: int = Field(default=3, description=\"Number of documents to return after reranking\")\n","\n","    class Config:\n","        arbitrary_types_allowed = True\n","\n","    def _get_relevant_documents(self, query: str) -> List[LangchainDocument]:\n","        # Initial retrieval\n","        initial_docs = self.vectorstore.similarity_search(query, k=self.k)\n","\n","        # Prepare pairs for cross-encoder\n","        pairs = [[query, doc.page_content] for doc in initial_docs]\n","\n","        # Get cross-encoder scores\n","        scores = self.cross_encoder.predict(pairs)\n","\n","        # Sort documents by score\n","        scored_docs = sorted(zip(initial_docs, scores), key=lambda x: x[1], reverse=True)\n","\n","        # Return top reranked documents\n","        return [doc for doc, _ in scored_docs[:self.rerank_top_k]]\n","\n","\n","    def get_relevant_documents(self, query: str) -> List[LangchainDocument]:\n","        # Initial retrieval\n","        initial_docs = self.vectorstore.similarity_search(query, k=self.k)\n","\n","        # Prepare pairs for cross-encoder\n","        pairs = [[query, doc.page_content] for doc in initial_docs]\n","\n","        # Get cross-encoder scores\n","        scores = self.cross_encoder.predict(pairs)\n","\n","        # Sort documents by score\n","        scored_docs = sorted(zip(initial_docs, scores), key=lambda x: x[1], reverse=True)\n","\n","        # Return top reranked documents\n","        return [doc for doc, _ in scored_docs[:self.rerank_top_k]]\n","\n","    async def aget_relevant_documents(self, query: str) -> List[LangchainDocument]:\n","        raise NotImplementedError(\"Async retrieval not implemented\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vusG18j7_x83","executionInfo":{"status":"ok","timestamp":1769073572073,"user_tz":-420,"elapsed":754,"user":{"displayName":"Nguyen Thi Tra My B2207544","userId":"14497950818613580693"}},"outputId":"798c29cc-b3af-472d-df6f-29cea5278364"},"execution_count":159,"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-2459284724.py:3: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n","  class CrossEncoderRetriever(BaseRetriever, BaseModel):\n"]}]},{"cell_type":"markdown","source":["# Create an instance and showcase over an example"],"metadata":{"id":"JU0c4hXI_7fY"}},{"cell_type":"code","source":["# Create the cross-encoder retriever\n","cross_encoder_retriever = CrossEncoderRetriever(\n","    vectorstore=vectorstore,\n","    cross_encoder=cross_encoder,\n","    k=10,  # Retrieve 10 documents initially\n","    rerank_top_k=5  # Return top 5 after reranking\n",")\n","\n","# Set up the LLM\n","llm = ChatOpenAI(\n","    base_url=\"https://llm.ptnglobalcorp.com\",\n","    model=\"gpt-4.1\",\n","    temperature=0,\n","    max_tokens=4000,\n","    openai_api_key=userdata.get('key_ptn')\n",")\n","\n","# Create the RetrievalQA chain with the cross-encoder retriever\n","qa_chain = RetrievalQA.from_chain_type(\n","    llm=llm,\n","    chain_type=\"stuff\",\n","    retriever=cross_encoder_retriever,\n","    return_source_documents=True\n",")\n","\n","# Example query\n","query = \"What are the impacts of climate change on biodiversity?\"\n","result = qa_chain({\"query\": query})\n","\n","print(f\"\\nQuestion: {query}\")\n","print(f\"Answer: {result['result']}\")\n","print(\"\\nRelevant source documents:\")\n","for i, doc in enumerate(result[\"source_documents\"]):\n","    print(f\"\\nDocument {i+1}:\")\n","    print(doc.page_content[:200] + \"...\")  # Print first 200 characters of each document"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8pOx39Lx_7IO","executionInfo":{"status":"ok","timestamp":1769073639142,"user_tz":-420,"elapsed":9220,"user":{"displayName":"Nguyen Thi Tra My B2207544","userId":"14497950818613580693"}},"outputId":"7b2a41c6-f4e6-4f61-b9d2-5a516b68ae99"},"execution_count":162,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Question: What are the impacts of climate change on biodiversity?\n","Answer: content='Climate change impacts biodiversity by causing shifts in plant and animal species composition, leading to a loss of biodiversity and disrupting ecological balance. In marine ecosystems, rising sea temperatures, ocean acidification, and changing currents affect marine biodiversity, disrupt marine food webs, and impact fisheries. Freshwater ecosystems are affected by changes in precipitation patterns, temperature, and water flow, resulting in altered water quality, habitat loss, and reduced biodiversity. Overall, climate change contributes to ecosystem degradation and decreased availability of natural resources.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 98, 'prompt_tokens': 1279, 'total_tokens': 1377, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': None, 'reasoning_tokens': None, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_1a2c4a5ede', 'id': 'chatcmpl-D0l9gwQlpMZ4R7tMNT8gGomXGslrw', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019be501-6471-7081-84fd-2eebb5e64842-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 1279, 'output_tokens': 98, 'total_tokens': 1377, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}}\n","\n","Relevant source documents:\n","\n","Document 1:\n","experiencing shifts in plant and animal species composition. These changes can lead to a loss \n","of biodiversity and disrupt ecological balance. \n","Marine Ecosystems \n","Marine ecosystems are highly vulnerab...\n","\n","Document 2:\n","goals. Policies should promote synergies between biodiversity conservation and climate \n","action. \n","Chapter 10: Climate Change and Human Health \n","Health Impacts \n","Heat-Related Illnesses \n","Rising temperature...\n","\n","Document 3:\n","includes identifying climate refugia, areas less affected by climate change, and prioritizing \n","them for protection. Adaptive management practices ensure that conservation efforts remain \n","effective und...\n","\n","Document 4:\n","Local communities are often on the front lines of climate impacts and can be powerful agents \n","of change. Community-based conservation projects involve residents in protecting and \n","restoring natural re...\n","\n","Document 5:\n","Freshwater Ecosystems \n","Freshwater ecosystems, including rivers, lakes, and wetlands, are affected by changes in \n","precipitation patterns, temperature, and water flow. These changes can lead to altered ...\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"DVjzioUmAPzq"},"execution_count":null,"outputs":[]}]}