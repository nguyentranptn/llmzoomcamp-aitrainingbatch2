{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "q2wJSM5m68do",
        "outputId": "fef66e1f-a9d7-4980-a5ff-802e3534348f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.2.4)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.12/dist-packages (1.1.7)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.2.0)\n",
            "Requirement already satisfied: langchain_classic in /usr/local/lib/python3.12/dist-packages (1.0.1)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.12/dist-packages (0.4.1)\n",
            "Requirement already satisfied: rank_bm25 in /usr/local/lib/python3.12/dist-packages (0.2.2)\n",
            "Requirement already satisfied: fitz in /usr/local/lib/python3.12/dist-packages (0.0.1.dev2)\n",
            "Requirement already satisfied: tools in /usr/local/lib/python3.12/dist-packages (1.0.21)\n",
            "Requirement already satisfied: deepeval in /usr/local/lib/python3.12/dist-packages (3.8.1)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.12/dist-packages (6.6.2)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.2.1 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.2.7)\n",
            "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.6)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.12.3)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (2.15.0)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.9.0+cpu)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.36.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain_classic) (1.1.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain_classic) (0.6.4)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain_classic) (6.0.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain_classic) (2.32.5)\n",
            "Requirement already satisfied: sqlalchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_classic) (2.0.45)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (3.13.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.12.0)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: configobj in /usr/local/lib/python3.12/dist-packages (from fitz) (5.0.9)\n",
            "Requirement already satisfied: configparser in /usr/local/lib/python3.12/dist-packages (from fitz) (7.2.0)\n",
            "Requirement already satisfied: httplib2 in /usr/local/lib/python3.12/dist-packages (from fitz) (0.31.1)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.12/dist-packages (from fitz) (5.3.3)\n",
            "Requirement already satisfied: nipype in /usr/local/lib/python3.12/dist-packages (from fitz) (1.10.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from fitz) (2.2.2)\n",
            "Requirement already satisfied: pyxnat in /usr/local/lib/python3.12/dist-packages (from fitz) (1.6.4)\n",
            "Requirement already satisfied: click<8.3.0,>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from deepeval) (8.2.1)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.67.1 in /usr/local/lib/python3.12/dist-packages (from deepeval) (1.76.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from deepeval) (3.1.6)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.12/dist-packages (from deepeval) (1.6.0)\n",
            "Requirement already satisfied: opentelemetry-api<2.0.0,>=1.24.0 in /usr/local/lib/python3.12/dist-packages (from deepeval) (1.39.1)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0 in /usr/local/lib/python3.12/dist-packages (from deepeval) (1.39.1)\n",
            "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.24.0 in /usr/local/lib/python3.12/dist-packages (from deepeval) (1.39.1)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.12/dist-packages (from deepeval) (3.2.0)\n",
            "Requirement already satisfied: posthog<6.0.0,>=5.4.0 in /usr/local/lib/python3.12/dist-packages (from deepeval) (5.4.0)\n",
            "Requirement already satisfied: pyfiglet in /usr/local/lib/python3.12/dist-packages (from deepeval) (1.0.4)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.12/dist-packages (from deepeval) (8.4.2)\n",
            "Requirement already satisfied: pytest-asyncio in /usr/local/lib/python3.12/dist-packages (from deepeval) (1.3.0)\n",
            "Requirement already satisfied: pytest-repeat in /usr/local/lib/python3.12/dist-packages (from deepeval) (0.9.4)\n",
            "Requirement already satisfied: pytest-rerunfailures in /usr/local/lib/python3.12/dist-packages (from deepeval) (16.1)\n",
            "Requirement already satisfied: pytest-xdist in /usr/local/lib/python3.12/dist-packages (from deepeval) (3.8.0)\n",
            "Requirement already satisfied: rich<15.0.0,>=13.6.0 in /usr/local/lib/python3.12/dist-packages (from deepeval) (13.9.4)\n",
            "Requirement already satisfied: sentry-sdk in /usr/local/lib/python3.12/dist-packages (from deepeval) (2.49.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from deepeval) (75.2.0)\n",
            "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from deepeval) (0.9.0)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.9 in /usr/local/lib/python3.12/dist-packages (from deepeval) (0.21.1)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.12/dist-packages (from deepeval) (0.45.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.22.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (3.26.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.20.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (25.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (1.33)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (0.13.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (4.0.0)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.6)\n",
            "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.3.3)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.17->langchain_classic) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.17->langchain_classic) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.17->langchain_classic) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.17->langchain_classic) (0.25.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api<2.0.0,>=1.24.0->deepeval) (8.7.1)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval) (1.72.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.39.1 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval) (1.39.1)\n",
            "Requirement already satisfied: opentelemetry-proto==1.39.1 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval) (1.39.1)\n",
            "Requirement already satisfied: protobuf<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-proto==1.39.1->opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval) (5.29.5)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.60b1 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk<2.0.0,>=1.24.0->deepeval) (0.60b1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=5.4.0->deepeval) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.2 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=5.4.0->deepeval) (2.9.0.post0)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=5.4.0->deepeval) (2.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->langchain_classic) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->langchain_classic) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->langchain_classic) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->langchain_classic) (2026.1.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich<15.0.0,>=13.6.0->deepeval) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich<15.0.0,>=13.6.0->deepeval) (2.19.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy<3.0.0,>=1.4.0->langchain_classic) (3.3.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.11.3)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.6.1)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.9->deepeval) (1.5.4)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2->fitz) (3.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->deepeval) (3.0.3)\n",
            "Requirement already satisfied: prov>=1.5.2 in /usr/local/lib/python3.12/dist-packages (from nipype->fitz) (2.1.1)\n",
            "Requirement already satisfied: pydot>=1.2.3 in /usr/local/lib/python3.12/dist-packages (from nipype->fitz) (4.0.1)\n",
            "Requirement already satisfied: rdflib>=5.0.0 in /usr/local/lib/python3.12/dist-packages (from nipype->fitz) (7.5.0)\n",
            "Requirement already satisfied: simplejson>=3.8.0 in /usr/local/lib/python3.12/dist-packages (from nipype->fitz) (3.20.2)\n",
            "Requirement already satisfied: traits>=6.2 in /usr/local/lib/python3.12/dist-packages (from nipype->fitz) (7.1.0)\n",
            "Requirement already satisfied: acres in /usr/local/lib/python3.12/dist-packages (from nipype->fitz) (0.5.0)\n",
            "Requirement already satisfied: etelemetry>=0.3.1 in /usr/local/lib/python3.12/dist-packages (from nipype->fitz) (0.3.1)\n",
            "Requirement already satisfied: looseversion!=1.2 in /usr/local/lib/python3.12/dist-packages (from nipype->fitz) (1.3.0)\n",
            "Requirement already satisfied: puremagic in /usr/local/lib/python3.12/dist-packages (from nipype->fitz) (1.30)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->fitz) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->fitz) (2025.3)\n",
            "Requirement already satisfied: iniconfig>=1 in /usr/local/lib/python3.12/dist-packages (from pytest->deepeval) (2.3.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.12/dist-packages (from pytest->deepeval) (1.6.0)\n",
            "Requirement already satisfied: execnet>=2.1 in /usr/local/lib/python3.12/dist-packages (from pytest-xdist->deepeval) (2.1.2)\n",
            "Requirement already satisfied: lxml>=4.3 in /usr/local/lib/python3.12/dist-packages (from pyxnat->fitz) (6.0.2)\n",
            "Requirement already satisfied: pathlib>=1.0 in /usr/local/lib/python3.12/dist-packages (from pyxnat->fitz) (1.0.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: ci-info>=0.2 in /usr/local/lib/python3.12/dist-packages (from etelemetry>=0.3.1->nipype->fitz) (0.3.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.17->langchain_classic) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.17->langchain_classic) (0.16.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api<2.0.0,>=1.24.0->deepeval) (3.23.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.1->langchain) (3.0.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich<15.0.0,>=13.6.0->deepeval) (0.1.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain_community) (1.1.0)\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install langchain langchain-openai python-dotenv sentence-transformers langchain_classic langchain_community langchain_community rank_bm25 fitz tools deepeval pypdf faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone the repository to access helper functions and evaluation modules\n",
        "!git clone https://github.com/NirDiamant/RAG_TECHNIQUES.git\n",
        "import sys\n",
        "sys.path.append('RAG_TECHNIQUES')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5py9KAe27Zmb",
        "outputId": "a63a12a8-c9aa-450a-c8b5-af282cd26f9d",
        "collapsed": true
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'RAG_TECHNIQUES'...\n",
            "remote: Enumerating objects: 1769, done.\u001b[K\n",
            "remote: Counting objects: 100% (1105/1105), done.\u001b[K\n",
            "remote: Compressing objects: 100% (417/417), done.\u001b[K\n",
            "remote: Total 1769 (delta 735), reused 690 (delta 688), pack-reused 664 (from 4)\u001b[K\n",
            "Receiving objects: 100% (1769/1769), 36.51 MiB | 14.09 MiB/s, done.\n",
            "Resolving deltas: 100% (1121/1121), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "from dotenv import load_dotenv\n",
        "from langchain_core.documents import Document\n",
        "from typing import List, Dict, Any, Tuple\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_classic.chains import RetrievalQA\n",
        "from langchain_core.retrievers import BaseRetriever\n",
        "from sentence_transformers import CrossEncoder\n",
        "from google.colab import userdata\n",
        "\n",
        "# Ensure the RAG_TECHNIQUES directory is in the path for this cell\n",
        "if 'RAG_TECHNIQUES' not in sys.path:\n",
        "    sys.path.append('RAG_TECHNIQUES')\n",
        "\n",
        "# Use for collab - Set OpenAI API key environment variables FIRST\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "os.environ[\"OPENAI_API_BASE_URL\"] = userdata.get('OPENAI_API_BASE_URL')\n",
        "\n",
        "# Original path append replaced for Colab compatibility\n",
        "from helper_functions import *\n",
        "from evaluation.evalute_rag import *\n",
        "\n",
        "# Load environment variables from a .env file\n",
        "# load_dotenv()\n",
        "\n",
        "# Set the OpenAI API key environment variable (these are now redundant if using userdata.get)\n",
        "# os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')\n",
        "# os.environ[\"OPENAI_API_BASE_URL\"] = os.getenv('OPENAI_API_BASE_URL')\n"
      ],
      "metadata": {
        "id": "FFgEnj6M95Yl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3608d251-81d9-482e-f1ff-2fd161bfbab1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download required data files\n",
        "import os\n",
        "os.makedirs('data', exist_ok=True)\n",
        "\n",
        "# Download the PDF document used in this notebook\n",
        "!wget -O data/Understanding_Climate_Change.pdf https://raw.githubusercontent.com/NirDiamant/RAG_TECHNIQUES/main/data/Understanding_Climate_Change.pdf\n",
        "!wget -O data/Understanding_Climate_Change.pdf https://raw.githubusercontent.com/NirDiamant/RAG_TECHNIQUES/main/data/Understanding_Climate_Change.pdf\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "EJFcD7r999iI",
        "outputId": "7ac114cb-fd75-4b5a-b9a8-b24f12736ac1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-01-27 07:05:27--  https://raw.githubusercontent.com/NirDiamant/RAG_TECHNIQUES/main/data/Understanding_Climate_Change.pdf\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 206372 (202K) [application/octet-stream]\n",
            "Saving to: ‘data/Understanding_Climate_Change.pdf’\n",
            "\n",
            "data/Understanding_ 100%[===================>] 201.54K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2026-01-27 07:05:27 (7.97 MB/s) - ‘data/Understanding_Climate_Change.pdf’ saved [206372/206372]\n",
            "\n",
            "--2026-01-27 07:05:27--  https://raw.githubusercontent.com/NirDiamant/RAG_TECHNIQUES/main/data/Understanding_Climate_Change.pdf\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 206372 (202K) [application/octet-stream]\n",
            "Saving to: ‘data/Understanding_Climate_Change.pdf’\n",
            "\n",
            "data/Understanding_ 100%[===================>] 201.54K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2026-01-27 07:05:27 (7.21 MB/s) - ‘data/Understanding_Climate_Change.pdf’ saved [206372/206372]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"data/Understanding_Climate_Change.pdf\""
      ],
      "metadata": {
        "id": "yp8YNaEj_VUI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1f81301a"
      },
      "source": [
        "import os\n",
        "# from langchain_openai import OpenAIEmbeddings # Remove OpenAI Embeddings\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings # Import HuggingFace Embeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "# This function redefines the encode_pdf logic to explicitly pass the OpenAI API base URL to OpenAIEmbeddings,\n",
        "# addressing potential configuration issues or custom endpoint requirements.\n",
        "def encode_pdf_remake(path, chunk_size=1000, chunk_overlap=200):\n",
        "  \"\"\"\n",
        "  Encodes a PDF book into a vector store using HuggingFace embeddings.\n",
        "\n",
        "  Args:\n",
        "      path: The path to the PDF file.\n",
        "      chunk_size: The desired size of each text chunk.\n",
        "      chunk_overlap: The amount of overlap between consecutive chunks.\n",
        "\n",
        "  Returns:\n",
        "      A FAISS vector store containing the encoded book content.\n",
        "  \"\"\"\n",
        "\n",
        "  # Load PDF documents\n",
        "  loader = PyPDFLoader(path)\n",
        "  documents = loader.load()\n",
        "\n",
        "  # Split documents into chunks\n",
        "  text_splitter = RecursiveCharacterTextSplitter(\n",
        "      chunk_size=chunk_size, chunk_overlap=chunk_overlap, length_function=len\n",
        "  )\n",
        "  texts = text_splitter.split_documents(documents)\n",
        "  cleaned_texts = replace_t_with_space(texts) # Assuming replace_t_with_space is available from helper_functions\n",
        "\n",
        "  # Create embeddings and vector store using HuggingFace Embeddings\n",
        "  # A common model is 'sentence-transformers/all-MiniLM-L6-v2'\n",
        "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "  vectorstore = FAISS.from_documents(cleaned_texts, embeddings)\n",
        "\n",
        "  return vectorstore"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore = encode_pdf_remake(path)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "AULyS5-7_ZH5"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Method 1: LLM based function to rerank the retrieved documents"
      ],
      "metadata": {
        "id": "tL7YRAoqtUK0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RatingScore(BaseModel):\n",
        "    relevance_score: float = Field(..., description=\"The relevance score of a document to a query.\")\n",
        "\n",
        "def rerank_documents(query: str, docs: List[Document], top_n: int = 3) -> List[Document]:\n",
        "    prompt_template = PromptTemplate(\n",
        "        input_variables=[\"query\", \"doc\"],\n",
        "        template=\"\"\"On a scale of 1-10, rate the relevance of the following document to the query. Consider the specific context and intent of the query, not just keyword matches.\n",
        "        Query: {query}\n",
        "        Document: {doc}\n",
        "        Relevance Score:\"\"\"\n",
        "    )\n",
        "\n",
        "    llm = ChatOpenAI(\n",
        "        api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
        "        base_url=os.getenv(\"OPENAI_API_BASE_URL\"),\n",
        "        temperature=0,\n",
        "        model_name=\"gpt-4.1\",\n",
        "        max_tokens=4000\n",
        "      )\n",
        "    llm_chain = prompt_template | llm.with_structured_output(RatingScore)\n",
        "\n",
        "    scored_docs = []\n",
        "    for doc in docs:\n",
        "        input_data = {\"query\": query, \"doc\": doc.page_content}\n",
        "        score = llm_chain.invoke(input_data).relevance_score\n",
        "        try:\n",
        "            score = float(score)\n",
        "        except ValueError:\n",
        "            score = 0  # Default score if parsing fails\n",
        "        scored_docs.append((doc, score))\n",
        "\n",
        "    reranked_docs = sorted(scored_docs, key=lambda x: x[1], reverse=True)\n",
        "    return [doc for doc, _ in reranked_docs[:top_n]]"
      ],
      "metadata": {
        "id": "g38vvRx3_gQH"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What are the impacts of climate change on biodiversity?\"\n",
        "initial_docs = vectorstore.similarity_search(query, k=15)\n",
        "reranked_docs = rerank_documents(query, initial_docs)\n",
        "\n",
        "# print first 3 initial documents\n",
        "print(\"Top initial documents:\")\n",
        "for i, doc in enumerate(initial_docs[:3]):\n",
        "    print(f\"\\nDocument {i+1}:\")\n",
        "    print(doc.page_content[:200] + \"...\")  # Print first 200 characters of each document\n",
        "\n",
        "\n",
        "# Print results\n",
        "print(f\"Query: {query}\\n\")\n",
        "print(\"Top reranked documents:\")\n",
        "for i, doc in enumerate(reranked_docs):\n",
        "    print(f\"\\nDocument {i+1}:\")\n",
        "    print(doc.page_content[:200] + \"...\")  # Print first 200 characters of each document"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEeoChLLCJ_B",
        "outputId": "4407e0d7-df90-4d2a-efb2-50f1931a61a7",
        "collapsed": true
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top initial documents:\n",
            "\n",
            "Document 1:\n",
            "Climate change is altering terrestrial ecosystems by shifting habitat ranges, changing species \n",
            "distributions, and impacting ecosystem functions. Forests, grasslands, and deserts are \n",
            "experiencing shi...\n",
            "\n",
            "Document 2:\n",
            "protection, and habitat creation. \n",
            "Climate-Resilient Conservation \n",
            "Conservation strategies must account for climate change impacts to be effective. This \n",
            "includes identifying climate refugia, areas le...\n",
            "\n",
            "Document 3:\n",
            "The economic costs of climate change include damage to infrastructure, reduced agricultural \n",
            "productivity, health care costs, and lost labor productivity. Extreme weather events, such as \n",
            "hurricanes a...\n",
            "Query: What are the impacts of climate change on biodiversity?\n",
            "\n",
            "Top reranked documents:\n",
            "\n",
            "Document 1:\n",
            "Climate change is altering terrestrial ecosystems by shifting habitat ranges, changing species \n",
            "distributions, and impacting ecosystem functions. Forests, grasslands, and deserts are \n",
            "experiencing shi...\n",
            "\n",
            "Document 2:\n",
            "Coral reefs are highly sensitive to changes in temperature and acidity. Ocean acidification \n",
            "and warming waters contribute to coral bleaching and mortality, threatening biodiversity and \n",
            "fisheries. Pr...\n",
            "\n",
            "Document 3:\n",
            "Freshwater Ecosystems \n",
            "Freshwater ecosystems, including rivers, lakes, and wetlands, are affected by changes in \n",
            "precipitation patterns, temperature, and water flow. These changes can lead to altered ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a custom retriever class\n",
        "class CustomRetriever(BaseRetriever, BaseModel):\n",
        "\n",
        "    vectorstore: Any = Field(description=\"Vector store for initial retrieval\")\n",
        "\n",
        "    class Config:\n",
        "        arbitrary_types_allowed = True\n",
        "\n",
        "    def _get_relevant_documents(self, query: str, num_docs=2) -> List[Document]:\n",
        "        initial_docs = self.vectorstore.similarity_search(query, k=30)\n",
        "        return rerank_documents(query, initial_docs, top_n=num_docs)\n",
        "\n",
        "\n",
        "# Create the custom retriever\n",
        "custom_retriever = CustomRetriever(vectorstore=vectorstore)\n",
        "\n",
        "# Create an LLM for answering questions\n",
        "llm = ChatOpenAI(\n",
        "  api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
        "  base_url=os.getenv(\"OPENAI_API_BASE_URL\"),\n",
        "  temperature=0,\n",
        "  model_name=\"gpt-4.1\",\n",
        "  max_tokens=4000\n",
        ")\n",
        "\n",
        "# Create the RetrievalQA chain with the custom retriever\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=custom_retriever,\n",
        "    return_source_documents=True\n",
        ")"
      ],
      "metadata": {
        "id": "82qKzM2ZFAxS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68fccd80-e179-4da8-c105-162623d230ba"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4244753332.py:2: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n",
            "  class CustomRetriever(BaseRetriever, BaseModel):\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = qa_chain({\"query\": query})\n",
        "\n",
        "print(f\"\\nQuestion: {query}\")\n",
        "print(f\"Answer: {result['result']}\")\n",
        "print(\"\\nRelevant source documents:\")\n",
        "for i, doc in enumerate(result[\"source_documents\"]):\n",
        "    print(f\"\\nDocument {i+1}:\")\n",
        "    print(doc.page_content[:200] + \"...\")  # Print first 200 characters of each document"
      ],
      "metadata": {
        "id": "quQOiuQzFF1T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "411ef325-0b82-49bd-f3a4-c6216b7b30f9"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-546735038.py:1: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain-classic 0.1.0 and will be removed in 1.0. Use `invoke` instead.\n",
            "  result = qa_chain({\"query\": query})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Question: What are the impacts of climate change on biodiversity?\n",
            "Answer: Climate change has significant impacts on biodiversity, including:\n",
            "\n",
            "1. **Shifting Habitat Ranges:** As temperatures rise and precipitation patterns change, many species are forced to move to new areas where conditions are more suitable. This can lead to changes in the composition of forests, grasslands, and deserts.\n",
            "\n",
            "2. **Changing Species Distributions:** Some species may expand their range, while others may contract or even disappear from certain areas. This disrupts existing ecological balances and can lead to the loss of native species.\n",
            "\n",
            "3. **Loss of Biodiversity:** The disruption of habitats and ecosystems can result in a decline in the number and variety of species, threatening overall biodiversity.\n",
            "\n",
            "4. **Disrupted Ecosystem Functions:** Changes in species composition and abundance can impact ecosystem functions such as pollination, nutrient cycling, and food web dynamics.\n",
            "\n",
            "5. **Marine Ecosystem Impacts:** In the oceans, rising temperatures, acidification, and changing currents affect marine biodiversity. Coral reefs, in particular, are highly sensitive and face bleaching and mortality, which threatens the many species that depend on them.\n",
            "\n",
            "6. **Disrupted Food Webs:** Changes in species migration and reproductive cycles can disrupt food webs, affecting both marine and terrestrial ecosystems.\n",
            "\n",
            "Overall, climate change threatens biodiversity by altering habitats, disrupting species interactions, and increasing the risk of extinction for many plants and animals.\n",
            "\n",
            "Relevant source documents:\n",
            "\n",
            "Document 1:\n",
            "Climate change is altering terrestrial ecosystems by shifting habitat ranges, changing species \n",
            "distributions, and impacting ecosystem functions. Forests, grasslands, and deserts are \n",
            "experiencing shi...\n",
            "\n",
            "Document 2:\n",
            "Coral reefs are highly sensitive to changes in temperature and acidity. Ocean acidification \n",
            "and warming waters contribute to coral bleaching and mortality, threatening biodiversity and \n",
            "fisheries. Pr...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chunks = [\n",
        "    \"The capital of France is great.\",\n",
        "    \"The capital of France is huge.\",\n",
        "    \"The capital of France is beautiful.\",\n",
        "    \"\"\"Have you ever visited Paris? It is a beautiful city where you can eat delicious food and see the Eiffel Tower.\n",
        "    I really enjoyed all the cities in france, but its capital with the Eiffel Tower is my favorite city.\"\"\",\n",
        "    \"I really enjoyed my trip to Paris, France. The city is beautiful and the food is delicious. I would love to visit again. Such a great capital city.\"\n",
        "]\n",
        "docs = [Document(page_content=sentence) for sentence in chunks]\n",
        "\n",
        "\n",
        "def compare_rag_techniques(query: str, docs: List[Document] = docs) -> None:\n",
        "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "    vectorstore = FAISS.from_documents(docs, embeddings)\n",
        "\n",
        "    print(\"Comparison of Retrieval Techniques\")\n",
        "    print(\"==================================\")\n",
        "    print(f\"Query: {query}\\n\")\n",
        "\n",
        "    print(\"Baseline Retrieval Result:\")\n",
        "    baseline_docs = vectorstore.similarity_search(query, k=2)\n",
        "    for i, doc in enumerate(baseline_docs):\n",
        "        print(f\"\\nDocument {i+1}:\")\n",
        "        print(doc.page_content)\n",
        "\n",
        "    print(\"\\nAdvanced Retrieval Result:\")\n",
        "    custom_retriever = CustomRetriever(vectorstore=vectorstore)\n",
        "    advanced_docs = custom_retriever._get_relevant_documents(query)\n",
        "    for i, doc in enumerate(advanced_docs):\n",
        "        print(f\"\\nDocument {i+1}:\")\n",
        "        print(doc.page_content)\n",
        "\n",
        "\n",
        "query = \"what is the capital of france?\"\n",
        "compare_rag_techniques(query, docs)"
      ],
      "metadata": {
        "id": "I2sPqBCaF4cH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4f5b5e1-5704-4137-b394-e502537d07c7"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparison of Retrieval Techniques\n",
            "==================================\n",
            "Query: what is the capital of france?\n",
            "\n",
            "Baseline Retrieval Result:\n",
            "\n",
            "Document 1:\n",
            "The capital of France is huge.\n",
            "\n",
            "Document 2:\n",
            "The capital of France is great.\n",
            "\n",
            "Advanced Retrieval Result:\n",
            "\n",
            "Document 1:\n",
            "The capital of France is great.\n",
            "\n",
            "Document 2:\n",
            "The capital of France is huge.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Method 2: Cross Encoder models"
      ],
      "metadata": {
        "id": "CfLcN2Lntrt2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
        "\n",
        "class CrossEncoderRetriever(BaseRetriever, BaseModel):\n",
        "    vectorstore: Any = Field(description=\"Vector store for initial retrieval\")\n",
        "    cross_encoder: Any = Field(description=\"Cross-encoder model for reranking\")\n",
        "    k: int = Field(default=5, description=\"Number of documents to retrieve initially\")\n",
        "    rerank_top_k: int = Field(default=3, description=\"Number of documents to return after reranking\")\n",
        "\n",
        "    class Config:\n",
        "        arbitrary_types_allowed = True\n",
        "\n",
        "    def _get_relevant_documents(self, query: str) -> List[Document]:\n",
        "        # Initial retrieval\n",
        "        initial_docs = self.vectorstore.similarity_search(query, k=self.k)\n",
        "\n",
        "        # Prepare pairs for cross-encoder\n",
        "        pairs = [[query, doc.page_content] for doc in initial_docs]\n",
        "\n",
        "        # Get cross-encoder scores\n",
        "        scores = self.cross_encoder.predict(pairs)\n",
        "\n",
        "        # Sort documents by score\n",
        "        scored_docs = sorted(zip(initial_docs, scores), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        # Return top reranked documents\n",
        "        return [doc for doc, _ in scored_docs[:self.rerank_top_k]]\n",
        "\n",
        "    async def aget_relevant_documents(self, query: str) -> List[Document]:\n",
        "        raise NotImplementedError(\"Async retrieval not implemented\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZolddMNTtstv",
        "outputId": "c7ac9357-793a-4225-803a-21b3212c424b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3795157466.py:3: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n",
            "  class CrossEncoderRetriever(BaseRetriever, BaseModel):\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the cross-encoder retriever\n",
        "cross_encoder_retriever = CrossEncoderRetriever(\n",
        "    vectorstore=vectorstore,\n",
        "    cross_encoder=cross_encoder,\n",
        "    k=10,  # Retrieve 10 documents initially\n",
        "    rerank_top_k=5  # Return top 5 after reranking\n",
        ")\n",
        "\n",
        "# Set up the LLM\n",
        "llm = ChatOpenAI(\n",
        "  api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
        "  base_url=os.getenv(\"OPENAI_API_BASE_URL\"),\n",
        "  temperature=0,\n",
        "  model_name=\"gpt-4.1\",\n",
        "  max_tokens=4000\n",
        ")\n",
        "\n",
        "# Create the RetrievalQA chain with the cross-encoder retriever\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=cross_encoder_retriever,\n",
        "    return_source_documents=True\n",
        ")\n",
        "\n",
        "# Example query\n",
        "query = \"What are the impacts of climate change on biodiversity?\"\n",
        "result = qa_chain({\"query\": query})\n",
        "\n",
        "print(f\"\\nQuestion: {query}\")\n",
        "print(f\"Answer: {result['result']}\")\n",
        "print(\"\\nRelevant source documents:\")\n",
        "for i, doc in enumerate(result[\"source_documents\"]):\n",
        "    print(f\"\\nDocument {i+1}:\")\n",
        "    print(doc.page_content[:200] + \"...\")  # Print first 200 characters of each document"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Kqnh07JPvsuy",
        "outputId": "146e10e4-a4de-4d2f-e06a-c7b027ffb503"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Question: What are the impacts of climate change on biodiversity?\n",
            "Answer: Climate change has significant impacts on biodiversity, affecting both terrestrial and marine ecosystems. Here are the main impacts:\n",
            "\n",
            "**1. Shifts in Habitat Ranges and Species Distributions:**  \n",
            "As temperatures rise and precipitation patterns change, many plant and animal species are forced to move to new areas where conditions are more suitable. This can lead to changes in the composition of forests, grasslands, deserts, and other ecosystems.\n",
            "\n",
            "**2. Loss of Biodiversity:**  \n",
            "These shifts can result in the loss of species that are unable to adapt or migrate quickly enough, leading to reduced biodiversity and the potential extinction of vulnerable species.\n",
            "\n",
            "**3. Disruption of Ecosystem Functions:**  \n",
            "Changes in species composition can disrupt ecological balance and the functions that ecosystems provide, such as pollination, nutrient cycling, and water regulation.\n",
            "\n",
            "**4. Marine Ecosystem Vulnerability:**  \n",
            "Rising sea temperatures, ocean acidification, and changing ocean currents affect marine biodiversity. Coral reefs, for example, are highly sensitive to temperature changes and acidification, which can lead to coral bleaching and loss of habitat for many marine species.\n",
            "\n",
            "**5. Disruption of Food Webs:**  \n",
            "Species migration and changes in reproductive cycles can disrupt food webs, affecting both terrestrial and marine ecosystems. This can have cascading effects on fisheries and human communities that depend on them.\n",
            "\n",
            "**6. Increased Risk of Invasive Species:**  \n",
            "As native species decline or move, invasive species may take advantage of the changing conditions, further threatening local biodiversity.\n",
            "\n",
            "**7. Need for Climate-Resilient Conservation:**  \n",
            "Conservation strategies must adapt to these changes by identifying and protecting climate refugia (areas less affected by climate change) and using adaptive management practices to ensure the continued effectiveness of conservation efforts.\n",
            "\n",
            "In summary, climate change threatens biodiversity by altering habitats, shifting species distributions, disrupting ecosystem functions, and increasing the risk of species loss and ecosystem imbalance.\n",
            "\n",
            "Relevant source documents:\n",
            "\n",
            "Document 1:\n",
            "Climate change is altering terrestrial ecosystems by shifting habitat ranges, changing species \n",
            "distributions, and impacting ecosystem functions. Forests, grasslands, and deserts are \n",
            "experiencing shi...\n",
            "\n",
            "Document 2:\n",
            "protection, and habitat creation. \n",
            "Climate-Resilient Conservation \n",
            "Conservation strategies must account for climate change impacts to be effective. This \n",
            "includes identifying climate refugia, areas le...\n",
            "\n",
            "Document 3:\n",
            "goals. Policies should promote synergies between biodiversity conservation and climate \n",
            "action. \n",
            "Chapter 10: Climate Change and Human Health \n",
            "Health Impacts \n",
            "Heat-Related Illnesses \n",
            "Rising temperature...\n",
            "\n",
            "Document 4:\n",
            "Local communities are often on the front lines of climate impacts and can be powerful agents \n",
            "of change. Community-based conservation projects involve residents in protecting and \n",
            "restoring natural re...\n",
            "\n",
            "Document 5:\n",
            "cultural perceptions. \n",
            "Youth Engagement \n",
            "Youth are vital stakeholders in climate action. Empowering young people through education, \n",
            "activism, and leadership opportunities can drive transformative cha...\n"
          ]
        }
      ]
    }
  ]
}