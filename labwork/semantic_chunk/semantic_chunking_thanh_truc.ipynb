{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "DM2mrTSwxsY7",
        "outputId": "632b0297-f4b1-4d99-df9e-64873f8cd150"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-experimental\n",
            "  Downloading langchain_experimental-0.4.1-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-1.1.7-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
            "Requirement already satisfied: rank_bm25 in /usr/local/lib/python3.12/dist-packages (0.2.2)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-experimental) (1.2.7)\n",
            "Collecting langchain-community<1.0.0,>=0.4.0 (from langchain-experimental)\n",
            "  Downloading langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (2.15.0)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rank_bm25) (2.0.2)\n",
            "Collecting langchain-classic<2.0.0,>=1.0.0 (from langchain-community<1.0.0,>=0.4.0->langchain-experimental)\n",
            "  Downloading langchain_classic-1.0.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community<1.0.0,>=0.4.0->langchain-experimental) (2.0.45)\n",
            "Collecting requests<3.0.0,>=2.32.5 (from langchain-community<1.0.0,>=0.4.0->langchain-experimental)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community<1.0.0,>=0.4.0->langchain-experimental) (6.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community<1.0.0,>=0.4.0->langchain-experimental) (3.13.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community<1.0.0,>=0.4.0->langchain-experimental) (9.1.2)\n",
            "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community<1.0.0,>=0.4.0->langchain-experimental)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community<1.0.0,>=0.4.0->langchain-experimental) (2.12.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community<1.0.0,>=0.4.0->langchain-experimental) (0.6.4)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community<1.0.0,>=0.4.0->langchain-experimental) (0.4.3)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-experimental) (1.33)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-experimental) (25.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-experimental) (2.12.3)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-experimental) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-experimental) (0.13.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.11.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (1.22.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai<3.0.0,>=1.109.1->langchain-openai) (3.11)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community<1.0.0,>=0.4.0->langchain-experimental)\n",
            "  Downloading marshmallow-3.26.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community<1.0.0,>=0.4.0->langchain-experimental)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain-openai) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain-openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain-openai) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain-experimental) (3.0.0)\n",
            "Collecting langchain-text-splitters<2.0.0,>=1.1.0 (from langchain-classic<2.0.0,>=1.0.0->langchain-community<1.0.0,>=0.4.0->langchain-experimental)\n",
            "  Downloading langchain_text_splitters-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.0->langchain-experimental) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.0->langchain-experimental) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.0->langchain-experimental) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (3.3.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community<1.0.0,>=0.4.0->langchain-experimental)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain_experimental-0.4.1-py3-none-any.whl (210 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.1/210.1 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-1.1.7-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.8/84.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading langchain_classic-1.0.1-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-1.1.0-py3-none-any.whl (34 kB)\n",
            "Downloading marshmallow-3.26.2-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: requests, mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain-text-splitters, langchain-openai, langchain-classic, langchain-community, langchain-experimental\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 langchain-classic-1.0.1 langchain-community-0.4.1 langchain-experimental-0.4.1 langchain-openai-1.1.7 langchain-text-splitters-1.1.0 marshmallow-3.26.2 mypy-extensions-1.1.0 requests-2.32.5 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install langchain-experimental langchain-openai python-dotenv rank_bm25 fitz tools deepeval PyMuPDF faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone the repository to access helper functions and evaluation modules\n",
        "!git clone https://github.com/NirDiamant/RAG_TECHNIQUES.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Q3Sp9ZtXx9dQ",
        "outputId": "9f6c2d60-3ded-40de-fdc3-bddfbaa2e327"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'RAG_TECHNIQUES'...\n",
            "remote: Enumerating objects: 1769, done.\u001b[K\n",
            "remote: Counting objects: 100% (1105/1105), done.\u001b[K\n",
            "remote: Compressing objects: 100% (417/417), done.\u001b[K\n",
            "remote: Total 1769 (delta 735), reused 690 (delta 688), pack-reused 664 (from 4)\u001b[K\n",
            "Receiving objects: 100% (1769/1769), 36.51 MiB | 30.62 MiB/s, done.\n",
            "Resolving deltas: 100% (1121/1121), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/RAG_TECHNIQUES')"
      ],
      "metadata": {
        "id": "xJoAJGfwJWSX"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "SLLjg7zfKQSH",
        "outputId": "d2d2e67f-b383-41b6-895c-8963ddf303ae"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.13.2-cp310-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Downloading faiss_cpu-1.13.2-cp310-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (23.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.8/23.8 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.13.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "from langchain_experimental.text_splitter import SemanticChunker\n",
        "from google.colab import userdata\n",
        "\n",
        "# Use for collab - Set OpenAI API key environment variables FIRST\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "os.environ[\"OPENAI_API_BASE_URL\"] = userdata.get('OPENAI_API_BASE_URL')\n",
        "\n",
        "# Original path append replaced for Colab compatibility\n",
        "from helper_functions import *\n",
        "from evaluation.evalute_rag import *\n",
        "\n",
        "# Load environment variables from a .env file\n",
        "# load_dotenv()\n",
        "\n",
        "# Set the OpenAI API key environment variable\n",
        "# os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "OvVCWHzYx_If"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download required data files\n",
        "import os\n",
        "os.makedirs('data', exist_ok=True)\n",
        "\n",
        "# Download the PDF document used in this notebook\n",
        "!wget -O data/Understanding_Climate_Change.pdf https://raw.githubusercontent.com/NirDiamant/RAG_TECHNIQUES/main/data/Understanding_Climate_Change.pdf\n",
        "!wget -O data/Understanding_Climate_Change.pdf https://raw.githubusercontent.com/NirDiamant/RAG_TECHNIQUES/main/data/Understanding_Climate_Change.pdf\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "gYqeILeiyMtx",
        "outputId": "21669375-e96b-46d3-e9c1-a5652be88ba6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-01-27 16:01:15--  https://raw.githubusercontent.com/NirDiamant/RAG_TECHNIQUES/main/data/Understanding_Climate_Change.pdf\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 206372 (202K) [application/octet-stream]\n",
            "Saving to: ‘data/Understanding_Climate_Change.pdf’\n",
            "\n",
            "data/Understanding_ 100%[===================>] 201.54K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2026-01-27 16:01:15 (7.96 MB/s) - ‘data/Understanding_Climate_Change.pdf’ saved [206372/206372]\n",
            "\n",
            "--2026-01-27 16:01:15--  https://raw.githubusercontent.com/NirDiamant/RAG_TECHNIQUES/main/data/Understanding_Climate_Change.pdf\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 206372 (202K) [application/octet-stream]\n",
            "Saving to: ‘data/Understanding_Climate_Change.pdf’\n",
            "\n",
            "data/Understanding_ 100%[===================>] 201.54K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2026-01-27 16:01:15 (7.42 MB/s) - ‘data/Understanding_Climate_Change.pdf’ saved [206372/206372]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"data/Understanding_Climate_Change.pdf\""
      ],
      "metadata": {
        "id": "h5hoNXAHyP1X"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.embeddings import HuggingFaceEmbeddings # Import HuggingFace Embeddings\n",
        "import fitz # Import PyMuPDF\n",
        "def read_pdf_to_string(path):\n",
        "    \"\"\"\n",
        "    Read a PDF document from the specified path and return its content as a string.\n",
        "\n",
        "    Args:\n",
        "        path (str): The file path to the PDF document.\n",
        "\n",
        "    Returns:\n",
        "        str: The concatenated text content of all pages in the PDF document.\n",
        "\n",
        "    The function uses the 'fitz' library (PyMuPDF) to open the PDF document, iterate over each page,\n",
        "    extract the text content from each page, and append it to a single string.\n",
        "    \"\"\"\n",
        "    # Open the PDF document located at the specified path\n",
        "    doc = fitz.open(path)\n",
        "    content = \"\"\n",
        "    # Iterate over each page in the document\n",
        "    for page_num in range(len(doc)):\n",
        "        # Get the current page\n",
        "        page = doc[page_num]\n",
        "        # Extract the text content from the current page and append it to the content string\n",
        "        content += page.get_text()\n",
        "    return content"
      ],
      "metadata": {
        "id": "bGPxkWLHyjXn"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "content = read_pdf_to_string(path)"
      ],
      "metadata": {
        "id": "rm6C6rIdyTH4"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_experimental.text_splitter import SemanticChunker\n",
        "\n",
        "text_splitter = SemanticChunker(\n",
        "  HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\"),\n",
        "  breakpoint_threshold_type='percentile',\n",
        "  breakpoint_threshold_amount=90\n",
        ") # chose which embeddings and breakpoint type and threshold to use"
      ],
      "metadata": {
        "collapsed": true,
        "id": "mge2WUTGzBPo"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = text_splitter.create_documents([content])"
      ],
      "metadata": {
        "id": "ukQEQtxsz0Af"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "vectorstore = FAISS.from_documents(docs, embeddings)\n",
        "chunks_query_retriever = vectorstore.as_retriever(search_kwargs={\"k\": 2})"
      ],
      "metadata": {
        "id": "WpDAETEfz5BO"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_context_per_question_remake(question, chunks_query_retriever):\n",
        "    \"\"\"\n",
        "    Retrieves relevant context and unique URLs for a given question using the chunks query retriever.\n",
        "\n",
        "    Args:\n",
        "        question: The question for which to retrieve context and URLs.\n",
        "\n",
        "    Returns:\n",
        "        A tuple containing:\n",
        "        - A string with the concatenated content of relevant documents.\n",
        "        - A list of unique URLs from the metadata of the relevant documents.\n",
        "    \"\"\"\n",
        "\n",
        "    # Retrieve relevant documents for the given question\n",
        "    docs = chunks_query_retriever.invoke(question)\n",
        "\n",
        "    # Concatenate document content\n",
        "    # context = \" \".join(doc.page_content for doc in docs)\n",
        "    context = [doc.page_content for doc in docs]\n",
        "\n",
        "    return context"
      ],
      "metadata": {
        "id": "LSjNDC6BPFCU"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from helper_functions import *\n",
        "\n",
        "test_query = \"What is the main cause of climate change?\"\n",
        "context = retrieve_context_per_question_remake(test_query, chunks_query_retriever)\n",
        "show_context(context)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJjpWDaNz-hf",
        "outputId": "4194fc17-293f-4800-bb53-a47168211c04"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context 1:\n",
            "These effects include: \n",
            "Rising Temperatures \n",
            "Global temperatures have risen by about 1.2 degrees Celsius (2.2 degrees Fahrenheit) since \n",
            "the late 19th century. This warming is not uniform, with some regions experiencing more \n",
            "significant increases than others. Heatwaves \n",
            "Heatwaves are becoming more frequent and severe, posing risks to human health, agriculture, \n",
            "and infrastructure. Cities are particularly vulnerable due to the \"urban heat island\" effect. Heatwaves can lead to heat-related illnesses and exacerbate existing health conditions. Changing Seasons \n",
            "Climate change is altering the timing and length of seasons, affecting ecosystems and human \n",
            "activities. For example, spring is arriving earlier, and winters are becoming shorter and \n",
            "milder in many regions. This shift disrupts plant and animal life cycles and agricultural \n",
            "practices. Melting Ice and Rising Sea Levels \n",
            "Warmer temperatures are causing polar ice caps and glaciers to melt, contributing to rising \n",
            "sea levels. Sea levels have risen by about 20 centimeters (8 inches) in the past century, \n",
            "threatening coastal communities and ecosystems. Polar Ice Melt \n",
            "The Arctic is warming at more than twice the global average rate, leading to significant ice \n",
            "loss. Antarctic ice sheets are also losing mass, contributing to sea level rise. This melting \n",
            "affects global ocean currents and weather patterns. Glacial Retreat \n",
            "Glaciers around the world are retreating, affecting water supplies for millions of people. Regions dependent on glacial meltwater, such as the Himalayas and the Andes, face \n",
            "particular risks. Glacial melt also impacts hydropower generation and agriculture. Coastal Erosion \n",
            "Rising sea levels and increased storm surges are accelerating coastal erosion, threatening \n",
            "homes, infrastructure, and ecosystems. Low-lying islands and coastal regions are especially \n",
            "vulnerable. Coastal communities must invest in adaptation measures like sea walls and \n",
            "managed retreats. Extreme Weather Events \n",
            "Climate change is linked to an increase in the frequency and severity of extreme weather \n",
            "events, such as hurricanes, heatwaves, droughts, and heavy rainfall. These events can have \n",
            "devastating impacts on communities, economies, and ecosystems. Hurricanes and Typhoons \n",
            "Warmer ocean temperatures can intensify hurricanes and typhoons, leading to more \n",
            "destructive storms. Coastal regions are at heightened risk of storm surge and flooding. Early \n",
            "warning systems and resilient infrastructure are critical for mitigating these risks. Droughts \n",
            "Increased temperatures and changing precipitation patterns are contributing to more frequent \n",
            "and severe droughts. This affects agriculture, water supply, and ecosystems, particularly in \n",
            "arid and semi-arid regions. Droughts can lead to food and water shortages and exacerbate \n",
            "conflicts. Flooding \n",
            "Heavy rainfall events are becoming more common, leading to increased flooding. Urban \n",
            "areas with poor drainage and infrastructure are particularly at risk. Flood management \n",
            "strategies include improved drainage systems, green infrastructure, and floodplain restoration. Ocean Acidification \n",
            "Increased CO2 levels in the atmosphere lead to higher concentrations of CO2 in the oceans. This causes the water to become more acidic, which can harm marine life, particularly \n",
            "organisms with calcium carbonate shells or skeletons, such as corals and some shellfish. Coral Reefs \n",
            "Coral reefs are highly sensitive to changes in temperature and acidity. Ocean acidification \n",
            "and warming waters contribute to coral bleaching and mortality, threatening biodiversity and \n",
            "fisheries. Protecting and restoring coral reefs is essential for marine conservation. Marine Ecosystems \n",
            "Acidification affects the health and survival of various marine species, disrupting food webs \n",
            "and ecosystems. This has implications for commercial fisheries and the livelihoods of people \n",
            "who depend on the ocean.\n",
            "\n",
            "\n",
            "Context 2:\n",
            "Understanding Climate Change \n",
            "Chapter 1: Introduction to Climate Change \n",
            "Climate change refers to significant, long-term changes in the global climate. The term \n",
            "\"global climate\" encompasses the planet's overall weather patterns, including temperature, \n",
            "precipitation, and wind patterns, over an extended period. Over the past century, human \n",
            "activities, particularly the burning of fossil fuels and deforestation, have significantly \n",
            "contributed to climate change. Historical Context \n",
            "The Earth's climate has changed throughout history. Over the past 650,000 years, there have \n",
            "been seven cycles of glacial advance and retreat, with the abrupt end of the last ice age about \n",
            "11,700 years ago marking the beginning of the modern climate era and human civilization. Most of these climate changes are attributed to very small variations in Earth's orbit that \n",
            "change the amount of solar energy our planet receives. During the Holocene epoch, which \n",
            "began at the end of the last ice age, human societies flourished, but the industrial era has seen \n",
            "unprecedented changes. Modern Observations \n",
            "Modern scientific observations indicate a rapid increase in global temperatures, sea levels, \n",
            "and extreme weather events. The Intergovernmental Panel on Climate Change (IPCC) has \n",
            "documented these changes extensively. Ice core samples, tree rings, and ocean sediments \n",
            "provide a historical record that scientists use to understand past climate conditions and \n",
            "predict future trends. The evidence overwhelmingly shows that recent changes are primarily \n",
            "driven by human activities, particularly the emission of greenhouse gases. Chapter 2: Causes of Climate Change \n",
            "Greenhouse Gases \n",
            "The primary cause of recent climate change is the increase in greenhouse gases in the \n",
            "atmosphere. Greenhouse gases, such as carbon dioxide (CO2), methane (CH4), and nitrous \n",
            "oxide (N2O), trap heat from the sun, creating a \"greenhouse effect.\" This effect is essential \n",
            "for life on Earth, as it keeps the planet warm enough to support life. However, human \n",
            "activities have intensified this natural process, leading to a warmer climate. Fossil Fuels \n",
            "Burning fossil fuels for energy releases large amounts of CO2. This includes coal, oil, and \n",
            "natural gas used for electricity, heating, and transportation. The industrial revolution marked \n",
            "the beginning of a significant increase in fossil fuel consumption, which continues to rise \n",
            "today. Coal \n",
            "Coal is the most carbon-intensive fossil fuel, and its use for electricity generation is a major \n",
            "source of CO2 emissions. Despite a decline in some regions, coal remains a significant \n",
            "energy source globally. It is mined extensively in countries like China, India, and the United \n",
            "States, contributing significantly to their energy supplies and CO2 footprints. Oil \n",
            "Oil is used primarily for transportation fuels, such as gasoline and diesel. The combustion of \n",
            "oil products releases significant amounts of CO2 and other pollutants, contributing to climate \n",
            "change and air quality issues.\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}