from typing import List
import os
from tqdm import tqdm

from langchain_classic.docstore.document import Document as LangchainDocument
from langchain_classic.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores.utils import DistanceStrategy

from src.chunking.chunk_documents import chunk_documents


def load_or_build_faiss_index(
    langchain_docs: List[LangchainDocument],
    chunk_size: int,
    embedding_model_name: str = "thenlper/gte-small",
    index_root_path: str = "./data/indexes",
    batch_size: int = 32,   
) -> FAISS:
    """
    Load a FAISS index if it exists, otherwise build it with progress bar.
    """

    # 1Ô∏è‚É£ Init embedding model (CPU-safe)
    embedding_model = HuggingFaceEmbeddings(
        model_name=embedding_model_name,
        multi_process=False,          # ‚ùó Windows-safe
        model_kwargs={"device": "cpu"},
        encode_kwargs={"normalize_embeddings": True},
    )

    # 2Ô∏è‚É£ Build index path
    index_name = (
        f"index_chunk_{chunk_size}_"
        f"embeddings_{embedding_model_name.replace('/', '~')}"
    )
    index_path = os.path.join(index_root_path, index_name)

    # 3Ô∏è‚É£ Load existing index
    if os.path.isdir(index_path):
        print(f"‚úÖ Loading existing FAISS index from {index_path}")
        return FAISS.load_local(
            index_path,
            embedding_model,
            distance_strategy=DistanceStrategy.COSINE,
        )

    print("üß± FAISS index not found. Building a new one...")

    # 4Ô∏è‚É£ Split documents
    docs_processed = chunk_documents(
        chunk_size=chunk_size,
        knowledge_base=langchain_docs,
        tokenizer_name=embedding_model_name,
    )

    print(f"üìÑ Total chunks to embed: {len(docs_processed)}")

    # 5Ô∏è‚É£ Build FAISS index incrementally
    faiss_index = None

    for i in tqdm(
        range(0, len(docs_processed), batch_size),
        desc="üî® Building FAISS index",
    ):
        batch_docs = docs_processed[i : i + batch_size]

        if faiss_index is None:
            # First batch ‚Üí create index
            faiss_index = FAISS.from_documents(
                batch_docs,
                embedding_model,
                distance_strategy=DistanceStrategy.COSINE,
            )
        else:
            # Next batches ‚Üí add to index
            faiss_index.add_documents(batch_docs)

    # 6Ô∏è‚É£ Save index
    os.makedirs(index_path, exist_ok=True)
    faiss_index.save_local(index_path)

    print(f"‚úÖ FAISS index saved to {index_path}")

    return faiss_index
